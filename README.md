# Defile de l'Ecluse - Bird Migration Forecasts

[![python](https://img.shields.io/badge/-Python_3.8_%7C_3.9_%7C_3.10-blue?logo=python&logoColor=white)](https://github.com/pre-commit/pre-commit)
[![pytorch](https://img.shields.io/badge/PyTorch_2.0+-ee4c2c?logo=pytorch&logoColor=white)](https://pytorch.org/get-started/locally/)
[![lightning](https://img.shields.io/badge/-Lightning_2.0+-792ee5?logo=pytorchlightning&logoColor=white)](https://pytorchlightning.ai/)
[![hydra](https://img.shields.io/badge/Config-Hydra_1.3-89b8cd)](https://hydra.cc/)

This work is based on [lightning-hydra-template](https://github.com/ashleve/lightning-hydra-template/tree/main/.github)<br>

## Project Structure

The directory structure of new project looks like this:

```
├── .github                   <- Github Actions workflows
│
├── configs                   <- Hydra configs
│   ├── callbacks                <- Callbacks configs
│   ├── data                     <- Data configs
│   ├── debug                    <- Debugging configs
│   ├── experiment               <- Experiment configs
|   ├── export                   <- Export configs
│   ├── extras                   <- Extra utilities configs
│   ├── hparams_search           <- Hyperparameter search configs
│   ├── hydra                    <- Hydra configs
│   ├── logger                   <- Logger configs
│   ├── model                    <- Model configs
│   ├── paths                    <- Project paths configs
│   ├── trainer                  <- Trainer configs
│   │
│   ├── eval.yaml             <- Main config for evaluation
│   └── train.yaml            <- Main config for training
│
├── data                   <- Project data
│
├── logs                   <- Logs generated by hydra and lightning loggers
│
├── notebooks              <- Jupyter notebooks. Naming convention is a number (for ordering),
│                             the creator's initials, and a short `-` delimited description,
│                             e.g. `1.0-jqp-initial-data-exploration.ipynb`.
│
├── scripts                <- Shell scripts
│
├── src                    <- Source code
│   ├── data                     <- Data scripts
│   ├── export                   <- Export scripts
│   ├── models                   <- Model scripts
│   ├── utils                    <- Utility scripts
│   │
│   ├── eval.py                  <- Run evaluation
│   └── train.py                 <- Run training
│
├── tests                  <- Tests of any kind
│
├── .gitignore                <- List of files ignored by git
├── .pre-commit-config.yaml   <- Configuration of pre-commit hooks for code formatting
├── .project-root             <- File for inferring the position of project root directory
├── environment.yaml          <- File for installing conda environment
└── README.md
```

## Quickstart

```bash
# clone project
git clone https://github.com/AmedeeRoy/defile-migration-forecast
cd defile

# create conda environment with required dependencies
conda env create --file=environment.yaml

# Activate the environment
conda activate defile-env
```

## How to use

<details>
<summary><b>Train/Evaluate a model with default config</b></summary>

```bash
# train with default config
python src/train.py

# eval with default config
python src/eval.py
```

</details>

<details>
<summary><b>Override default config</b></summary>

```bash
# change existing parameters
python src/train.py model.net.nb_layer=5 trainer.max_epochs=10

# add new parameters with '+' sign
python train.py +model.new_param="owo"
```

</details>

<details>
<summary><b>Train on CPU, GPU, multi-GPU and TPU</b></summary>

```bash
# train on CPU
python train.py trainer=cpu

# train on 1 GPU
python train.py trainer=gpu

# train on TPU
python train.py +trainer.tpu_cores=8

# train with DDP (Distributed Data Parallel) (4 GPUs)
python train.py trainer=ddp trainer.devices=4

# train with DDP (Distributed Data Parallel) (8 GPUs, 2 nodes)
python train.py trainer=ddp trainer.devices=4 trainer.num_nodes=2

# simulate DDP on CPU processes
python train.py trainer=ddp_sim trainer.devices=2

# accelerate training on mac
python train.py trainer=mps
```

> **Warning**: Currently there are problems with DDP mode, read [this issue](https://github.com/ashleve/lightning-hydra-template/issues/393) to learn more.

</details>

<!-- deepspeed support still in beta
<details>
<summary><b>Optimize large scale models on multiple GPUs with Deepspeed</b></summary>

```bash
python train.py +trainer.
```

</details>
 -->

<details>
<summary><b>Attach some callbacks to run</b></summary>

```bash
python train.py callbacks=default
```

> **Note**: Callbacks can be used for things such as as model checkpointing, early stopping and [many more](https://pytorch-lightning.readthedocs.io/en/latest/extensions/callbacks.html#built-in-callbacks).

> **Note**: Callbacks configs are placed in [configs/callbacks/](configs/callbacks/).

</details>

<details>
<summary><b>Use different tricks available in Pytorch Lightning</b></summary>

```yaml
# gradient clipping may be enabled to avoid exploding gradients
python train.py +trainer.gradient_clip_val=0.5

# run validation loop 4 times during a training epoch
python train.py +trainer.val_check_interval=0.25

# accumulate gradients
python train.py +trainer.accumulate_grad_batches=10

# terminate training after 12 hours
python train.py +trainer.max_time="00:12:00:00"
```

> **Note**: PyTorch Lightning provides about [40+ useful trainer flags](https://pytorch-lightning.readthedocs.io/en/latest/common/trainer.html#trainer-flags).

</details>

<details>
<summary><b>Easily debug</b></summary>

```bash
# runs 1 epoch in default debugging mode
# changes logging directory to `logs/debugs/...`
# sets level of all command line loggers to 'DEBUG'
# enforces debug-friendly configuration
python train.py debug=default

# run 1 train, val and test loop, using only 1 batch
python train.py debug=fdr

# print execution time profiling
python train.py debug=profiler

# try overfitting to 1 batch
python train.py debug=overfit

# raise exception if there are any numerical anomalies in tensors, like NaN or +/-inf
python train.py +trainer.detect_anomaly=true

# use only 20% of the data
python train.py +trainer.limit_train_batches=0.2 \
+trainer.limit_val_batches=0.2 +trainer.limit_test_batches=0.2
```

> **Note**: Visit [configs/debug/](configs/debug/) for different debugging configs.

</details>

<details>
<summary><b>Resume training from checkpoint</b></summary>

```yaml
python train.py ckpt_path="/path/to/ckpt/name.ckpt"
```

> **Note**: Checkpoint can be either path or URL.

> **Note**: Currently loading ckpt doesn't resume logger experiment, but it will be supported in future Lightning release.

</details>

<details>
<summary><b>Evaluate checkpoint on test dataset</b></summary>

```yaml
python eval.py ckpt_path="/path/to/ckpt/name.ckpt"
```

> **Note**: Checkpoint can be either path or URL.

</details>

<details>
<summary><b>Optimize hyperparameters with Optuna</b></summary>

```bash
# this will run hyperparameter search defined in `configs/hparams_search/mnist_optuna.yaml`
# over chosen experiment config
python train.py -m hparams_search=defile_optuna
```

> **Note**: Using [Optuna Sweeper](https://hydra.cc/docs/next/plugins/optuna_sweeper) doesn't require you to add any boilerplate to your code, everything is defined in a [single config file](configs/hparams_search/mnist_optuna.yaml).

> **Warning**: Optuna sweeps are not failure-resistant (if one job crashes then the whole sweep crashes).

</details>

<details>
<summary><b>Execute run for multiple different seeds</b></summary>

```bash
python train.py -m seed=1,2,3,4,5 trainer.deterministic=True logger=csv tags=["benchmark"]
```

> **Note**: `trainer.deterministic=True` makes pytorch more deterministic but impacts the performance.

</details>

<br>

## Processing of the count data

### Species considered

- les cibles principales du suivi ont toujours été rapaces/ardéiformes/pigeons/corvidés ; le suivi des passereaux est hétérogène ; historiquement ils n'étaient presque pas noté ; durant la dernière décennie c'est un peu mieux mais le Défilé concentre peu les passereaux contrairement aux cols, et les observateurs ne sont pas toujours présent tôt le matin, donc l'exploitation des données est presque impossible.

### Data collected

- le dénominateur commun à chaque année depuis 1966 c'est un total/jour/espèce avec l'heure de début et heure de fin du suivi ; pour certaines années nous avons plus de détail (horaire) mais c'est hétérogène.
- les relevés météo n'ont jamais été numérisés, et rien n'était noté avant 2008.
- le nombre d'observateur actif par jour est noté de manière hétérogène depuis 2008 mais pas numérisé, donc la pression d'obs "réelle" n'est pas disponible
- les détails (age, sexe) ont été relevé de manière très hétérogène au fil du temps ; probablement exploitable pour le busard des roseaux depuis les années 2000, mais pour les autres espèces j'en doute

### Temporal coverage

- Le réel suivi quotidien a débuté en 1993, avant cela le suivi était plus ponctuel, très concentré sur les pigeons en octobre.
- Exception faite de 1983 et 1992, années pendant lesquelles la motivation de quelques observateurs a permis les premiers "vrai suivi".
- En 1993 le Dr Charvoz a commencé à suivre bénévolement tous les jours dès juillet, avec l'aide de J.P. Matérac, M. Maire et d'autres les week-end.
- Jusqu'en 2007 le suivi était assuré uniquement par les bénévoles.
- De 2008 à 2016 le suivi était assuré par un salarié de la LPO la semaine et par des bénévoles les week-end.
- Depuis 2017 le suivi est assurée par 2 salariés de la LPO du lundi au samedi et par des bénévoles les dimanches.

Nous avions saisit les données 1966-2007 du Dr Charvoz en décryptant au mieux ses fiches (écriture de médecin !) mais des infos se sont perdues.
Certains observateurs comme Lutz Lücker ont des souvenirs mémorables de migration des pigeons dont nous n'avons pas trace.

### Data collection

- de 2008 à 2016 on avait des fiches papiers standard pour noter par heure (heure locale), c'était donc saisie avec des totaux horaires. pour certaines journées il y a seulement un formulaire avec total jour
- de 2017 à 2020 on a de l'ultra-brute car saisie en direct avec Naturalist. donc pas d'heure de début et de fin de suivi dans les données (mais on a ça à coté), seulement l'heure de la saisie de la donnée, donc à quelques minutes près celle du passage des oiseaux "en majorité" car ce mode de saisie était appliqué la semaine par les spotteurs pour les journées assurées par les bénévoles il y a seulement un formulaire avec total jour.
- depuis 2021 on utilise l'appli Trektellen, faite pour le suivi de migration, contrairement à Naturalist, donc l'ultra brute existe encore mais j'ignore comment l'extraire, je ne peux extraire qu'un total jour depuis l'interface web.

### Data available

- all_data_défilé_tri_v2023: take data until 2013
- data_brute_DE_2014_2021: from 2014

## My modification

- Split data into (1) 1966-2013 providing daily count, (2) 2014-2016 providing hourly count based on data entered manually and (3) 2017-2021 data from Naturalist providing both list and manual entry.
- Fix startTime and endTime for 2014-2016:
  - 29.09.2014 et 11.10.2014 dans les données brut (data_brute_DE_2014_2021)
  - 09.10.2015, 01.12.2016 et 03.12.2016 dans pressure observation (all_data_défilé_tri_v2023)
- Fix and align startTime and endTime for 2017-2021
  - some sightings were providing without a list and without time. so probably seen during the day, but couldn't assign to a hour slot
  - 2-3 instances of interruption of list during the day: 29.10.2021, 17.11.2021 and 14.09.2017
  - Many case of sightings submitted before startTime or after endTime according to pressure observation. In most case I modified pressure observation, but in some case I deleted time (probably sumbmitted from home?)
  - pressure observation also had about 10 entries which seemed completly wrong, I removed those and use the last/first sightings.
- Delete observations after 19:00 for 2020-9-10 (pressure effort states 19:00 as end time, but there were 3 observations after.)
- Delete the observation of a Marsh Harrier on the 2020-11-03 at 20:05 because this if after endtime
- Delete observations oon the 2021-10-29: time of observations don't make sense.
- Modify time slightly to match end time for 22.Sep.17 19:04 -> 18:59, 14.Sep.19 20:00 -> 19:59, 22.Sep.19 20:00 -> 19:59, 2021-09-02 20:00, 2021-10-20 18:00, 2021-09-01 20:00
